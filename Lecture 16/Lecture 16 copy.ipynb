{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> Lecture 16 - Practicing Chaining </span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "In this lecture you will get a chance to practice <br>\n",
    "the main dataset operations\n",
    "\n",
    "- There will be a quiz on this lecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> I. Import Libraries and Data </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results  = pd.read_csv(\"data_raw/results.csv\")\n",
    "races    = pd.read_csv(\"data_raw/races.csv\")\n",
    "results[\"points col\"] = results[\"points\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> II. Review Dataset Operations </span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "See attached file for a refresher on syntax\n",
    "\n",
    "```[] ``` $\\qquad \\qquad \\qquad \\quad$: Extracting columns <br>\n",
    "```.query() ``` $\\qquad \\qquad $: Subsetting rows <br>\n",
    "```.recode() ``` $ \\qquad \\quad \\ \\ $: Replacing values <br>\n",
    "```.groupby().agg() ```: Aggregate statistics by subgroup <br>\n",
    "```.rename() ``` $\\qquad \\quad \\ \\ $: Change name of columns\n",
    "\n",
    "Full list:\n",
    "\n",
    "<font size = \"4\">\n",
    "\n",
    "https://www.w3schools.com/python/pandas/pandas_ref_dataframe.asp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\"> III. Examples of Chaining </span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "The operations with \".\" are read left to right\n",
    "\n",
    "- Combine any of the above operations\n",
    "- Great way to make code efficient\n",
    "- The sky's the limit!\n",
    "\n",
    "\n",
    "Subsetting **before** extracting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driverId</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20320</th>\n",
       "      <td>4</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20344</th>\n",
       "      <td>18</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20368</th>\n",
       "      <td>20</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20392</th>\n",
       "      <td>18</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20416</th>\n",
       "      <td>17</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25740</th>\n",
       "      <td>830</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25760</th>\n",
       "      <td>830</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25780</th>\n",
       "      <td>830</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25800</th>\n",
       "      <td>847</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25820</th>\n",
       "      <td>830</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       driverId  points\n",
       "20320         4    25.0\n",
       "20344        18    25.0\n",
       "20368        20    25.0\n",
       "20392        18    25.0\n",
       "20416        17    25.0\n",
       "...         ...     ...\n",
       "25740       830    25.0\n",
       "25760       830    25.0\n",
       "25780       830    25.0\n",
       "25800       847    26.0\n",
       "25820       830    25.0\n",
       "\n",
       "[262 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data for drivers that scored more than 20 points on individual races\n",
    "# Then extract the columns \"driverId\" and \"points\"\n",
    "results.query('points >= 20')[[\"driverId\",\"points\"]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Subsetting **before** aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_points</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>constructorId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.148148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.904924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.203911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.910966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.012821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0.809028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>3.723684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2.327869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>3.693182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_points\n",
       "constructorId             \n",
       "1                 3.148148\n",
       "3                 1.904924\n",
       "4                 1.903226\n",
       "5                 1.203911\n",
       "6                 4.910966\n",
       "...                    ...\n",
       "209               0.012821\n",
       "210               0.809028\n",
       "211               3.723684\n",
       "213               2.327869\n",
       "214               3.693182\n",
       "\n",
       "[176 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This obtains a subset of drivers who competed in races 500 onwards\n",
    "# then computes the average by team (\"constructorId\")\n",
    "\n",
    "(results.query('raceId >= 500')\n",
    "        .groupby(\"constructorId\")\n",
    "        .agg(mean_points = (\"points\",\"mean\")))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Subsetting **after** aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_points</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>constructorId</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>12.363643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_points\n",
       "constructorId             \n",
       "131              12.363643"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This obtains the average points by team (\"constructorId\"), then \n",
    "# produces a subset of team whose average is higher than 10\n",
    "\n",
    "(results.groupby(\"constructorId\")\n",
    "        .agg(mean_points = (\"points\",\"mean\"))\n",
    "        .query('mean_points >= 10'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "Chaining inside queries + NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"is.na()\" produces a True/False vector, checking for missing values\n",
    "# \"is.notna()\" produces a True/False vector, checking for non-missing values\n",
    "# .str.isnumeric()\n",
    "results[\"points\"].isna()\n",
    "results[\"points\"].notna()\n",
    "\n",
    "subset_nas    = results.query('points.isna()')\n",
    "subset_nonnas = results.query('points.notna()')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:darkblue\"> III. Quiz Structure </span>\n",
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "The day of the quiz I will ...\n",
    "- Provide a dataset with information\n",
    "- Give more specific instructions.\n",
    "- Below, you will see the type of questions that will be asked.\n",
    "- The idea is for you to apply known concepts to new data\n",
    "- You have 50 minutes to complete the assignment\n",
    "\n",
    "Questions\n",
    "\n",
    "(exact wording may change in quiz, but exercise will be very similar)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font size = \"5\">\n",
    "\n",
    "(a) Replace the values of a column\n",
    "\n",
    "- Obtain unique string values of a column\n",
    "- Use the \".replace()\" command\n",
    "\n",
    "Hint: See Lecture 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#THESE ARE THE FIRST STEPS FOR EVERY ONE OF THEM\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('file_name.csv')\n",
    "\n",
    "#Step 1: Obtain unique string values of the column using the unique() method. For example, if you want to obtain the unique string values of a column named \"column_name\", you can do:\n",
    "\n",
    "unique_values = df['column_name'].unique()\n",
    "\n",
    "#Step 2: Create a dictionary that maps the old values to the new values that you want to replace them with. For example, if you want to replace \"old_value1\" with \"new_value1\" and \"old_value2\" with \"new_value2\", you can create the dictionary as follows:\n",
    "\n",
    "replace_dict = {\n",
    "    'old_value1': 'new_value1',\n",
    "    'old_value2': 'new_value2'\n",
    "}\n",
    "\n",
    "#Step 3: Finally, use the .replace() method to replace the old values with the new values in the column. You can use a for loop to iterate over each unique value in the column and replace it with the corresponding new value. For example:\n",
    "for value in unique_values:\n",
    "    df['column_name'] = df['column_name'].replace(value, replace_dict.get(value))\n",
    "\n",
    "#This will replace all the old values in the \"column_name\" column with the new values specified in the replace_dict dictionary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(b) Recode a numeric column\n",
    "\n",
    "- Use the \"pd.cut()\" command to create <br>\n",
    "a new column based on an interval.\n",
    "- See Lecture 14 for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat the pd.read_csv step\n",
    "\n",
    "# Step 1: Determine the intervals or bins for your numeric column. For example, if you have a numeric column named \"column_name\" and you want to bin it into three intervals, you can use the pd.cut() command as follows:\n",
    "\n",
    "bins = pd.cut(df['column_name'], 3)\n",
    "\n",
    "# Step 2: The pd.cut() command creates three intervals of equal width based on the range of the values in the \"column_name\" column. Create a new column in the DataFrame to store the binned values. For example, if you want to store the binned values in a new column named \"binned_column\", you can do:\n",
    "\n",
    "df['binned_column'] = bins\n",
    "\n",
    "# Step 3: This will add a new column to the DataFrame named \"binned_column\" containing the binned values. Finally, you can optionally rename the binned values using the labels parameter in pd.cut(). For example, if you want to rename the binned values as \"low\", \"medium\", and \"high\", you can do:\n",
    "\n",
    "bins = pd.cut(df['column_name'], 3, labels=['low', 'medium', 'high'])\n",
    "df['binned_column'] = bins\n",
    "\n",
    "# Overall: This will bin the values in the \"column_name\" column into three intervals with labels \"low\", \"medium\", and \"high\" and store the binned values in the new column named \"binned_column\".\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXAMPLE BELOW"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "Try it yourself!\n",
    "\n",
    "- Create a new variable \"hemisphere\"\n",
    "- Encode lattitude in (-90 and 0] as \"south\"\n",
    "- Encode lattitude in (0 and 90] as \"north\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_hemisphere = [-90,0,90]\n",
    "labels_hemisphere = [\"Southern hemisphere\",\"Northern Hemisphere\"]\n",
    "circuits[\"hemisphere\"] = pd.cut(circuits[\"lat\"],\n",
    "                                bins = bins_hemisphere,\n",
    "                                right = True,\n",
    "                                labels = labels_hemisphere)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(c) Aggregate and query\n",
    "\n",
    "- Use a combniation of the following commands <br>\n",
    "to produce a new dataset <br>\n",
    "``` .query() ``` <br>\n",
    "``` .groupby().agg() ``` <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Step 1: Use the .query() command to filter the dataset based on certain conditions. For example, if you want to select only the rows where the value of a variable named \"variable_name\" is greater than 10, you can do:\n",
    "#This will filter the dataset to include only the rows where the value of \"variable_name\" is greater than 10.\n",
    "\n",
    "df = df.query('variable_name > 10')\n",
    "\n",
    "#Step 2: Use the .groupby().agg() command to aggregate the variables in the dataset. For example, if you want to calculate the mean value of a variable named \"variable_name\" for each value of another variable named \"group_variable\", you can do:\n",
    "#This will group the dataset by the \"group_variable\" variable and calculate the mean value of \"variable_name\" for each group.\n",
    "\n",
    "grouped_df = df.groupby('group_variable').agg({'variable_name': 'mean'})\n",
    "\n",
    "#Step 3: Finally, you can optionally reset the index of the aggregated dataset using the .reset_index() command. For example, if you want to reset the index of the \"grouped_df\" dataset, you can do:\n",
    "\n",
    "grouped_df = grouped_df.reset_index()\n",
    "\n",
    "#This will reset the index of the \"grouped_df\" dataset to default integer values.\n",
    "#Overall, this combination of .query() and .groupby().agg() commands can be used to produce a new dataset that is filtered and aggregated based on certain conditions.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(d) Aggregate and sort\n",
    "\n",
    "- Use a combniation of the following commands <br>\n",
    "to produce a new dataset <br>\n",
    "``` .groupby().agg() ``` <br>\n",
    "``` .sort_values() ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Use the .groupby().agg() command to aggregate the variables in the dataset. For example, if you want to calculate the mean value of a variable named \"variable_name\" for each value of another variable named \"group_variable\", you can do:\n",
    "\n",
    "grouped_df = df.groupby('group_variable').agg({'variable_name': 'mean'})\n",
    "\n",
    "#Step 2: This will group the dataset by the \"group_variable\" variable and calculate the mean value of \"variable_name\" for each group.Use the .sort_values() command to sort the aggregated dataset based on certain variables. For example, if you want to sort the \"grouped_df\" dataset by the mean value of \"variable_name\" in descending order, you can do:\n",
    "\n",
    "sorted_df = grouped_df.sort_values(by='variable_name', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(e) Rename column\n",
    "\n",
    "- Create a dictionary\n",
    "- Rename one or more columns in a dataset <br>\n",
    "using the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Create a dictionary that maps the old column names to the new column names. For example, if you want to rename a column named \"old_column_name\" to \"new_column_name\", you can create a dictionary as follows:\n",
    "#This will create a dictionary that maps the old column name \"old_column_name\" to the new column name \"new_column_name\".\n",
    "\n",
    "column_name_dict = {'old_column_name': 'new_column_name'}\n",
    "\n",
    "#Step 2: Use the .rename() command to rename the columns in the dataset based on the dictionary. For example, if you want to rename the columns in the \"df\" dataset based on the \"column_name_dict\" dictionary, you can do:\n",
    "\n",
    "df = df.rename(columns=column_name_dict)\n",
    "\n",
    "#This will rename the columns in the \"df\" dataset based on the \"column_name_dict\" dictionary and store the renamed dataset in the \"df\" variable.\n",
    "#Overall, this approach allows you to rename one or more columns in a dataset using a dictionary that maps the old column names to the new column names.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size = \"5\">\n",
    "\n",
    "(f) Merge dataset\n",
    "\n",
    "- Use \"pd.merge\" to combine two datasets: <br>\n",
    "a primary and secondary\n",
    "- Only merge a subset of the columns of the <br>\n",
    "secondary dataset\n",
    "- Use \"display\" to show a the merged dataset,  <br>\n",
    "extracting a subset of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Next, read in the two datasets you want to merge. For example, if you have two datasets named \"primary_dataset.csv\" and \"secondary_dataset.csv\", you can read them in using the read_csv() method from pandas library as follows:\n",
    "\n",
    "primary_dataset = pd.read_csv('primary_dataset.csv')\n",
    "secondary_dataset = pd.read_csv('secondary_dataset.csv')\n",
    "\n",
    "#Step 2: Use the pd.merge() function to merge the two datasets. You can specify the primary dataset as the first argument, and the secondary dataset as the second argument. You can also specify the columns to merge on using the on parameter. For example, if you want to merge the datasets on a column named \"merge_column\", you can do:\n",
    "\n",
    "merged_dataset = pd.merge(primary_dataset, secondary_dataset[['merge_column', 'secondary_column']], on='merge_column')\n",
    "\n",
    "#This will display only the \"merge_column\" and \"primary_column\" columns of the merged dataset.\n",
    "#Overall, this approach allows you to merge two datasets in Python using the pd.merge() function, and select a subset of the columns to include in the merged dataset using the on and [['column_name']] parameters, and display a subset of columns using display() function.#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45fc1f684f6f416f40889115beff3ddf69879b64cf4bfee48cb72a61e9d15d1a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
